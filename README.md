# Сервис для анализа временных рядов

## Принцип работы

- Регистрация и вход
    - Пользователь проходит регистрацию или авторизацию в системе.
    - Каждый запрос к бекенду проверяет JWT токен пользователя.
- Загрузка данных
    - Пользователь загружает собственный временной ряд.
    - Сервис выполняет базовую проверку данных.
- Анализ временного ряда
    - Пользователь может выполнить статистический анализ загруженных данных.
    - Результаты анализа доступны для просмотра и скачивания.
- Прогнозирование
    - Пользователь выбирает модель прогнозирования.
    - Система рассчитывает будущие значения временного ряда.
    - Результаты прогнозирования можно скачать.
- Биллинг
    - У пользователя есть баланс в системе.
    - Средства списываются за проведённый анализ или прогноз.
- История и управление
    - Пользователь видит список загруженных временных рядов.
    - Доступны результаты предыдущих анализов и прогнозов.

## Демо

TODO

Сюда вставить скриншоты интерфейса, баз данных, а также ссылку на видео-демо.

## Компоненты системы

- Регистрация/аутентификация.
- Биллинг.
- Загрузка/скачивание временных рядов.
- Анализ временного ряда.
- Предсказание временного ряда.
- Интерфейс.

### Регистрация/аутентификация

Регистрация/аутентификация пользователя по логину и паролю.

Данный модуль реализован с помощью `FastAPI.security`, а именно используя парадингму OAuth2 на основе классов `OAuth2PasswordBearer`, `OAuth2PasswordRequestForm`. Делал я это по этим [официальным докам FastAPI](https://fastapi.tiangolo.com/tutorial/security/).

Принцип работы: 

- У меня есть бекенд (с различными эндпоинтами, реализованный через `FastAPI`) и фронтенд (реализованный на `streamlit`).
- В данном конкретном случае (т.н. *password flow в OAuth2*) бекенд будет как реализовывать API, так и проводить аутентификацию пользователя.
- Итак, алгоритм:
  - Пользователь вводит логин и пароль на фронтенде.
  - Фронтенд отправляет их в бекенд API.
  - Бекенд API проверяет данные и возвращает токен - строку, подтверждающую пользователя. Токен имеет некоторый lifetime. В качестве токена использую JWT (с помощью библиотеки `PyJWT`).
  - Фронтенд временно сохраняет токен.
  - При переходе на другую часть приложения фронтенд запрашивает данные у API и для авторизации отправляет в заголовке к запросу этот токен.
  - Бекенд API проверяет токен и если он действителен, то отдает данные.

Пароли хэшировать буду с помощью библиотеки `passlib`, используя алгоритм `Bcrypt`.

Для того, чтобы создавались секьюрные JWT необходимо создать secure random secret key с помощью этой команды:

```bash
openssl rand -hex 32
```

Результатом будет строка, которую требуется положить в файл `.env` с названием SECRET_KEY.

### Биллинг

У каждого пользователя есть баланс, который проверяется при попытке пользователя сделать анализ/предсказание по загруженному временному ряду.

Пополнение баланса сделано искусственное (пользователь может ввести любую сумму и баланс пополнится).

Стоимость услуг рассчитывается следующим образом:

- Бесплатно: загрузка, хранение, отображение, анализ, скачивание временных рядов.
- $ x_i \cdot length(timeseries) $, где $x_i$ - фиксированная цена предсказания одной временной точки (разная для каждой модели). То есть цена рассчитывается динамически в зависимости от требуемого пользователем горизонта прогнозирования. 

Вся информация о стоимости и о моделях находится в [models_info.json](./src/data/models_info.json) и подгружается в БД при ее старте в таблицу `models`. То есть для того, чтобы поменять тарифы потребуется лишь написать SQL-запросы которые изменят данные в таблице `models`.

### Загрузка/скачивание временных рядов

При загрузке пользователем временного ряда, данные проверяются на следование формату, пропуски и размеры. Если ряд удовлетворяет всем требованиям, то он сохраняется в базе данных (таблица `ts`).

Также есть возможность выгружать следующие временные ряды из базы данных:

- Исходный временной ряд, загруженный пользователем.
- Сглаженный с помощью EMA временной ряд.
- Предсказанные временной ряд моделью.

### Анализ временного ряда

Данный модуль будет проводить действия:

- Построение графиков:

  - Исходный временной ряд.
  - Сглаженный временной ряд (exponential moving average).

- Расчет простых статистик:

  - Среднее, медиана, стандартное отклонение, 25-й и 75-й квартили.
  - Минимальное и максимальное значения.
  - 3 наиболее и наименее частотные значения.

- Частотный анализ - наиболее значимые частоты используя преобразования Фурье.
- Статистические тесты:

  - Тест Манна-Кендалла на проверку наличия тренда. Также отобразим линейный тренд на исходном временном ряде.
  - Тест ARCH на проверку гетероскедастичности ряда. Также построим график остатков временного ряда от линейного тренда.

### Предсказание временного ряда

Данный модуль будет обучать статистические модели для предсказания временных рядов.

Все модели реализованы в библиотеке `statsforecast`:

- Модель экспоненциального скользящего среднего (ETS).
- Модель ARIMA.
- Модель Theta.
- Модель TBATS.

Также дадим предсказания наивными моделями:

- Модель среднего.
- Модель линейного тренда.

Предсказанные временные ряды будут сохранены в базе данных, отображены в интерфейсе, а также доступны для скачивания.

### Интерфейс

Использую библиотеку `streamlit` для построения интерфейса.

Интерфейс представляет собой несколько страниц (каждая страница - отдельный смысловой модуль, с общим контекстом и sidebar-ом). Разработка полностью основана на [этом официальном туториале библиотеки](https://docs.streamlit.io/get-started/tutorials/create-a-multipage-app).

В контексте интерфейса сохраняю следующие сущности (для сохранения сессионности и безопасности):

- JWT токен (который требуется для каждого эндпоинта, чтобы аутентифицировать пользователя).
- Модель данных текущего пользователя.
- Флаг аутентификации.

Использование библиотеки `streamlit` на каждый инстанс (например, открытую вкладку в браузере) создает отдельную сессию (внутри который мы уже используем JWT).

Страницы интерфейса:

- [login_page.py](./src/streamlit/login_page.py) - страница входа.
- [register.py](./src/streamlit/register_page.py) - страница регистрации.
- [im_page.py](./src/streamlit/im_page.py) - страница с личным кабинетом пользователя.
- [ts_page.py](./src/streamlit/ts_page.py) - страница анализа и предсказания временного ряда.

## Дизайн сервиса

### Бекенд

Весь бекэнд реализую с помощью `FastAPI` - это позволит обрабатывать все запросы к эндпоинтам (запросы на анализ и предсказание временного ряда будут попадать в очередь задач, чтобы не блокировать FastAPI клиент) в асинхронном режиме.

### Очереди задач для долгих вычислений

Использование очереди задач для анализа и предсказания нам нужны, чтобы не блокировать наш FastAPI клиент (будем ждать пока запрос посчитается). Поэтому при запросе на анализ/предсказание мы будем делать так:

- Эндпоинт принимает запрос в обработку и сразу возвращает job_id и status.
- Воркеры берут задачи из очереди, выполняют их и обновляют статус/результаты в базе данных.
- Интерфейс может опрашивать серверную часть для получения статуса задачи.

Соответственно для реализации этого использую:

- `Redis` - как хранилище очередей задач.
- `Redis Queue` - для управления задачами и запуска воркеров, которые выполняют вычисления (анализ и предсказание рядов).

Помимо основной очереди задач (реализованной с помощью `Redis`), я буду поддерживать таблицу `tasks` в `SQLite` для того, чтобы сохранять информацию о выполнении задач, а также фронтенд будет смотреть информацию из этой таблицы для получения статуса задач.

Для поддержания таблицы `tasks` есть специальный эндпоинт `/process_job_results`, который проходится по всем задачам в очереди и обновляет информацию о задаче в таблице `tasks`, а также выгружает в SQLite результаты задач. С помощью [скрипта redis_queue_watcher](./scripts/redis_queue_watcher.py) мы с маленькой периодичность обстреливаем этот эндпоинт.

### Работа с данными

Для хранения данных буду использовать in-memory БД `SQLite`, а для работы с БД библиотеку `SQLAlchemy`. Все сессии с БД сделаны асинхронными.

[Модели данных](./src/data_models.py)

Соответственно есть следующие модели данных в виде таблиц:

- users:
  - id
  - login
  - hashed_password: str
  - name - имя пользователя в сервисе
  - balance
  - time_series - список временных рядов, принадлежащих данному пользователю

- time_series:
  - id
  - user_id - id пользователя, которому принадлежит временной ряд
  - name - название временного ряда
  - created_at - дата создания временного ряда
  - length - длина временного ряда
  - data - сам временной ряд в формате list[float]
  - analysis_results - результаты анализа временного ряда в формате json
  - forecasting_ts - id-шники временных рядов предсказанных моделями

- models:
  - id
  - name - название модели
  - info - информация о модели
  - tariffs - стоимость использования модели (за одну точку пресказания) для предсказания временного ряда

- tasks:
  - id
  - user_id - id пользователя, которому принадлежит задача
  - ts_id - id временного ряда, которому принадлежит задача
  - type - тип задачи (analyze, forecast)
  - cost - стоимость задачи
  - status - статус задачи (queued, in_progress, done, failed)
  - params - параметры задачи (для анализа - пусто, для предсказания - количество точек предсказания и модель)
  - updated_at - дата обновления задачи

- forecasts:
  - id
  - model - название модели, использованная для предсказания временного ряда
  - fh - количество точек предсказания
  - data - результаты предсказания в формате json
  - created_at - дата создания задачи

## Структура проекта

```
├── demos - папка с фото и видео работы сервиса
├── dummy_ts - папка с тестовыми рядами
├── Project requirements.md
├── python-version
├── README.md
├── requirements.txt
├── scripts - полезные скрипты
│   ├── generate_ts.py - скрипт для генерации dummy временных рядов
│   └── redis_queue_watcher.py - скрипт для циклического вызова эндпоинта `/process_job_results` для синхронизации очереди Redis с SQLite (статусы задач и результаты работы задач)
└── src - основной код сервиса
    ├── app.py - FastAPI код, создание очереди Redis
    ├── contracts.py - контракты API
    ├── data - данные, подгружаемые в сервис (могут быть легко изменены)
    │   ├── models_info.json - информация о доступных моделях прогнозирования и их ценах
    │   ├── time_series_analysis_info.txt - справка по анализу рядов
    │   ├── time_series_forecasting_info.txt - справка по прогнозированию рядов
    │   └── time_series_requirements.txt - справка о требовании к формату рядов
    ├── data_models.py - модели данных для SQLite
    ├── db.py - создание БД, генератор сессии и различные запросы
    ├── security.py - модуль безопасности (хеширование паролей, JWT)
    ├── streamlit - код фронтенда на streamlit
    │   ├── api_calls.py - определение API запросов от фронта к бэку
    │   ├── app.py - определение страниц и сайдбара
    │   ├── im_page.py - страница с личным кабинетом (загрузка рядов, пополнение баланса)
    │   ├── login_page.py - страница с входом
    │   ├── prediction_tabs.py - функции для отображения предсказаний рядов и статуса задач предсказаний
    │   ├── register_page.py - страница с регистрацией
    │   ├── ts_loader_page.py - страница с загрузками рядов
    │   └── ts_page.py - страница с анализом и предсказаниями ряда
    ├── tasks.py - код для воркеров Redis Queue
    └── ts - модули работы с временным рядом
        ├── analyze.py - анализ ряда
        ├── forecast.py - обучение и предсказание будущих занчений ряда
        └── validate_series.py - валидация ряда
```

## Пример dotenv файла

```
# JWT settings
SECRET_KEY=RANDOM_SECRET_SECURE_KEY
ALGORITHM=HS256
ACESS_TOKEN_EXPIRE_MINUTES=30
# Backend URL
BACKEND_URL=http://localhost:8000
# Redis settings
REDIS_HOST=localhost
REDIS_PORT=6379
```

## Локальный запуск проекта

Для запуска проекта рекомендую следующий пайплайн:

Перейти в папку проекта:

```
cd time-series-analyzer
```

Скачать и установить Redis.

Скачать и установить miniconda.

Создать окружение с определенной версией питона:

```
conda create -n time-series-analyzer python==3.12
```

Активировать окружение:

```
conda activate time-series-analyzer
```

Установить зависимости:

```
pip install -r requirements.txt
```

Создать .env файл (как в примере выше) и положить его в корневую папку проекта.

Для запуска потребуется 5 сессий терминала:

1. Запускаем бекенд:

```
cd src && fastapi run app.py
```

2. Запускаем фронтенд:

```
cd src/streamlit && streamlit run app.py
```

3. Запускаем Redis сервер:

```
redis-server
```

4. Запускаем Redis воркера:

```
export OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES  &&  # только если на MacOS
cd src &&
rq worker
```

5. Запускаем cron-джобу для обноваления состояния SQLite:

```
cd scripts &&
python redis_queue_watcher.py
```

## Future considerations

- Добавить страницу с транзакциями пользователя (история баланса)
- Продумать пути в API и в соответствии с этим разделить логику по смыслу в разные модули (а не как сейчас все эндпоинты в одном `app.py`)
- Заменить in-memory БД на обычную
- Обернуть все в docker (backend, frontend (streamlit), redis, workers, redis_queue_watcher)
- Добавить более сложные модели прогнозирования
